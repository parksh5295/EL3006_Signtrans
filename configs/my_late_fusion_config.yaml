name: "late_fusion_experiment"

# ==============================================================================
# Data settings
# ==============================================================================
data:
  # train: "/home/work/asic-3/input_data/tsv_files_how2sign/tsv_files_how2sign/cvpr23.fairseq.i3d.train.how2sign.tsv"
  # dev: "/home/work/asic-3/input_data/tsv_files_how2sign/tsv_files_how2sign/cvpr23.fairseq.i3d.val.how2sign.tsv"
  # test: "/home/work/asic-3/input_data/tsv_files_how2sign/tsv_files_how2sign/cvpr23.fairseq.i3d.test.how2sign.tsv"
  train: "~/asic-3/input_data/csv_data/how2sign_realigned_train.csv"
  dev: "~/asic-3/input_data/csv_data/how2sign_realigned_val.csv"
  test: "~/asic-3/input_data/csv_data/how2sign_realigned_test.csv"
  
  # Vocabulary files
  # gls_vocab: "/home/work/asic-3/code/data/gloss.vocab"
  # txt_vocab: "/home/work/asic-3/code/data/text.vocab"
  gls_vocab: "~/asic-3/input_data/csv_data/gloss.vocab"
  txt_vocab: "~/asic-3/input_data/csv_data/text.vocab"

  # The path to the parent folder where the isolated features are stored.
  # TODO: Please verify these paths point to the correct OpenPose feature directories.
  sgn_dirs:
    # This order must match the order of model.encoder.late_fusion.feature_dims.
    # pose: "/home/work/asic-3/input_data/separated_features/pose"
    # hands: "/home/work/asic-3/input_data/separated_features/hands"
    # mouth: "/home/work/asic-3/input_data/separated_features/mouth"
    pose: "/path/to/your/split/openpose_features/pose"
    hands: "/path/to/your/split/openpose_features/hands"
    face: "/path/to/your/split/openpose_features/face"
  
  # Specify the column names in the tsv file (default values).
  # sequence_key: "id"
  #gls_key: "glosses"
  #txt_key: "translation"
  sequence_key: "SENTENCE_NAME"
  gls_key: "SENTENCE"
  txt_key: "SENTENCE"

  level: "word"
  txt_lowercase: true
  max_sent_length: 400

# ==============================================================================
# Training settings
# ==============================================================================
training:
  # The path to save all results (checkpoints, logs).
  model_dir: "/home/work/asic-3/output_data/late_fusion_run_20240321"
  
  # Whether to overwrite existing checkpoints.
  # overwrite: false
  overwrite: true
  
  # Random seed
  random_seed: 42
  
  # Training-related settings
  shuffle: true
  epochs: 300 # 5,000,000 is too large. Adjust the number of epochs appropriately.
  batch_size: 32
  batch_type: "sentence"
  batch_multiplier: 1
  
  # Scheduler settings
  scheduler:
    type: "warmup" # "plateau" or "warmup"
    warmup_steps: 4000
    k: 1.0 # warmup scheduler parameters
    # -- Plateau scheduler --
    # type: "plateau"
    # patience: 8
    # decrease_factor: 0.7
  
  # Optimizer settings
  optimizer:
    # Define parameters for Adam optimizer (betas, weight_decay, etc.).
    betas: [0.9, 0.998]
    weight_decay: 0.0
    
  learning_rate: 0.001
  learning_rate_min: 1.0e-07
  clipping_threshold: 1.0
  
  # Loss function weights
  recognition_loss_weight: 0.3
  # recognition_loss_weight: 0.0
  translation_loss_weight: 1.0
  
  # Validation and logging frequency
  validation_freq: 1000
  logging_freq: 100
  num_valid_log: 5
  
  # Earlyrstopping-relatedosettingsing-related settings
  early_stopping_metric: "bleu" # "bleu", "rouge", "wer" etc.tc.
  
  # Other settingsher settings
  label_smoothing: 0.1
  use_cuda: true
  eval_metric: "bleu"
  translation_max_output_length: 50
  
# ==============================================================================
# Model structure settings
# ==============================================================================
model:
  initializer: "xavier"
  bias_initializer: "zeros"
  init_gain: 1.0
  embed_initializer: "xavier"
  embed_init_gain: 1.0
  tied_softmax: false
  
  encoder:
    type: "transformer"
    num_layers: 6 # Increasing the number of layers is common.
    num_heads: 8
    hidden_size: 512
    ff_size: 2048
    dropout: 0.1
    emb_dropout: 0.1
    
    # Late Fusion settings
    late_fusion:
      enabled: true
      # Specify the feature dimensions in the order of sgn_dirs.
      # TODO: Please verify these match the actual dimensions of your OpenPose features.
      # feature_dims: [99, 126, 240]
      feature_dims: [75, 126, 210] # Example dimensions for [Pose, Hands, Face]

  decoder:
    type: "transformer"
    num_layers: 6
    num_heads: 8
    hidden_size: 512
    ff_size: 2048
    dropout: 0.1
    emb_dropout: 0.1
  
  # Spoken Language(Text) Embedding settings
  embeddings:
    embedding_dim: 512
    scale: false
    dropout: 0.1
    norm_type: "batch"
    activation_type: "softsign"

# ==============================================================================
# Testing
# ==============================================================================
testing:
    recognition_beam_sizes: [1, 2, 3, 4, 5]
    translation_beam_sizes: [1, 2, 3, 4, 5]
    translation_beam_alphas: [-1, 0, 1, 2]
    ckpts: ["best.ckpt"]
