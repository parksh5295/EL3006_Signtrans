name: "late_fusion_experiment"

# ==============================================================================
# Data settings
# ==============================================================================
data:
  # Hugging Face dataset identifier
  hf_dataset: "my-username/how2sign_keypoints"
  
  # Vocabulary files
  gls_vocab: "data/openpose/gloss.vocab"
  txt_vocab: "data/openpose/text.vocab"
  
  # Column names in the dataset
  sequence_key: "SENTENCE_NAME"
  gls_key: "SENTENCE"
  txt_key: "SENTENCE"
  
  # Feature columns in the Hugging Face dataset
  # This order must match the order of model.encoder.late_fusion.feature_dims.
  feature_keys: ["pose", "hands", "face"]

  level: "word"
  txt_lowercase: true
  max_sent_length: 400
  num_workers: 16 # Number of workers for data loading

# ==============================================================================
# Training settings
# ==============================================================================
training:
  # The path to save all results (checkpoints, logs).
  model_dir: "/home/work/asic-3/output_data/late_fusion_run_20240321"
  
  # Whether to overwrite existing checkpoints.
  # overwrite: false
  overwrite: true
  
  # Random seed
  random_seed: 42
  
  # Training-related settings
  shuffle: true
  epochs: 300 # 5,000,000 is too large. Adjust the number of epochs appropriately.
  batch_size: 32
  batch_type: "sentence"
  batch_multiplier: 1
  
  # Scheduler settings
  scheduler:
    type: "warmup" # "plateau" or "warmup"
    warmup_steps: 4000
    k: 1.0 # warmup scheduler parameters
    # -- Plateau scheduler --
    # type: "plateau"
    # patience: 8
    # decrease_factor: 0.7
  
  # Optimizer settings
  optimizer:
    # Define parameters for Adam optimizer (betas, weight_decay, etc.).
    betas: [0.9, 0.998]
    weight_decay: 0.0
    
  learning_rate: 0.001
  learning_rate_min: 1.0e-07
  clipping_threshold: 1.0
  
  # Loss function weights
  recognition_loss_weight: 0.3
  # recognition_loss_weight: 0.0
  translation_loss_weight: 1.0
  
  # Validation and logging frequency
  validation_freq: 1000
  logging_freq: 100
  num_valid_log: 5
  
  # Earlyrstopping-relatedosettingsing-related settings
  early_stopping_metric: "bleu" # "bleu", "rouge", "wer" etc.tc.
  
  # Other settingsher settings
  label_smoothing: 0.1
  use_cuda: true
  eval_metric: "bleu"
  translation_max_output_length: 50
  
# ==============================================================================
# Model structure settings
# ==============================================================================
model:
  initializer: "xavier"
  bias_initializer: "zeros"
  init_gain: 1.0
  embed_initializer: "xavier"
  embed_init_gain: 1.0
  tied_softmax: false
  
  encoder:
    type: "transformer"
    num_layers: 6 # Increasing the number of layers is common.
    num_heads: 8
    hidden_size: 512
    ff_size: 2048
    dropout: 0.1
    emb_dropout: 0.1
    
    # Late Fusion settings
    late_fusion:
      enabled: true
      # Specify the feature dimensions in the order of data.feature_keys.
      # TODO: Please verify these match the actual dimensions in your HF dataset.
      feature_dims: [75, 126, 210] # Example dimensions for [Pose, Hands, Face]

  decoder:
    type: "transformer"
    num_layers: 6
    num_heads: 8
    hidden_size: 512
    ff_size: 2048
    dropout: 0.1
    emb_dropout: 0.1
  
  # Spoken Language(Text) Embedding settings
  embeddings:
    embedding_dim: 512
    scale: false
    dropout: 0.1
    norm_type: "batch"
    activation_type: "softsign"

# ==============================================================================
# Testing
# ==============================================================================
testing:
    recognition_beam_sizes: [1, 2, 3, 4, 5]
    translation_beam_sizes: [1, 2, 3, 4, 5]
    translation_beam_alphas: [-1, 0, 1, 2]
    ckpts: ["best.ckpt"]
